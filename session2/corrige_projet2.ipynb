{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Corrigé Projet Maison 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import des modules usuels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement et traitement des données\n",
    "GEO = pd.read_csv(\"correspondance-code-insee-code-postal.csv\",\n",
    "                   sep=';',\n",
    "                   usecols=range(11),\n",
    "                   index_col=\"Code INSEE\")\n",
    "\n",
    "\n",
    "# A COMPLETER avec les colonnes\n",
    "# - lat, lon : latitude et longitude des communes\n",
    "# - cp_ville : Code Postal + \" \" + \"Commune\"\n",
    "GEO = (GEO.assign(**GEO.geo_point_2d.str.extract(\"(?P<lat>.*), (?P<lon>.*)\").astype(float))\n",
    "       .assign(cp_ville=lambda df: df[\"Code Postal\"] + ' ' + df[\"Commune\"])\n",
    "       .sort_index()\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie A**\n",
    "\n",
    "- Compléter le chargement des données en ajoutant au dataframe `GEO`\n",
    "    - les colonnes \"lat\" et \"lon\" avec la latitude et la longitude des communes\n",
    "    - une colonne \"cp_ville\" avec le Code Postal + un espace + et le nom de la Commune\n",
    "- Ecrire une fonction `search_city(lat, lon)` qui retourne le \"cp_ville\" de la commune la plus proche d'un point à partir de sa latitude et sa longitude.\n",
    "- Ecrire une fonction `dms2dec(deg, min, sec)` qui convertit les degrés, minutes, secondes en valeur numérique pour pouvoir utiliser la fonction précédente avec un GPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fonction recherche de ville\n",
    "def search_city(lat, long):\n",
    "    dist2 = ((GEO['lat']-lat)**2 + (GEO['lon']-long)**2)\n",
    "    return GEO.loc[dist2.idxmin(), \"cp_ville\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarques\n",
    "# 1)\n",
    "# boucles for pour calculer le min, pour collecter les résultats du parsing json, etc.\n",
    "# il faut éviter les boucles et utiliser les fonctions vectorielles de numpy et pandas\n",
    "# plus efficace, plus concis, pas de bug...\n",
    "# 2)\n",
    "# s.loc[s.idxmin()] vs s.loc[s==s.min()]\n",
    "# 3)\n",
    "# utiliser la distance euclidienne (approximation), éviter la distance de Manhattan..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'71330 BOSJEAN'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on applique la fonction à une coordonnée tirée au hasard\n",
    "np.random.seed(0)\n",
    "a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "lat = np.random.uniform(a, b)\n",
    "a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "lon = np.random.uniform(a, b)\n",
    "\n",
    "search_city(lat, lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# conversion degrés, minutes, secondes => décimal\n",
    "def dms2dec(deg, mn, sec):\n",
    "    return deg + mn / 60 + sec / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'91120 PALAISEAU'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# à partir de coordonnées GPS précises\n",
    "search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partie B**\n",
    "\n",
    "La colonne \"geo_shape\" comporte des chaines de catactères au format JSON. Elles représentent les formes géométriques des communes qui sont soit des polygones soit composées de plusieurs polygones.\n",
    "\n",
    "- Utiliser la librairie Python **json** pour parser les valeurs de la colonne \"geo_shape\" et mettre le résultat (`Series`) dans la variable `GEO_SHAPE`.\n",
    "- Ecrire une fonction `get_types()` qui retourne le décompte (`value_counts()`) des valeurs accédées avec la clé \"type\".\n",
    "- Ecrire une fonction `get_coordinates_len()` qui retourne le décompte (`value_counts()`) des longueurs des listes accédées avec la clé \"coordinates\".\n",
    "- Ecrire une fonction `get_most_complex_city()` qui retourne la commune est constituée du plus grand nombre de polygones ?\n",
    "- Ecrire une fonction `get_nb_cities_2_polygons()` qui retourne  le nombre de villes qui sont de type \"Polygon\" mais dont la longueur des listes accédées avec la clé \"coordinates\" vaut 2 ?\n",
    "- **Facultatif :**\n",
    "- Pour ces villes vérifier que le premier polygone contient bien le second (enclave). NB : on pourra installer la librairie **shapely**, utiliser la classe Polygon de **shapely.geometry**  et la méthode `contains()`. Sur Windows **shapely** peut nécessiter d'installer manuellement la dll \"geos_c.dll\" dans le répertoire \"Library/bin\" de votre environnement Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code INSEE\n",
       "01001    {'type': 'Polygon', 'coordinates': [[[4.926273...\n",
       "01002    {'type': 'Polygon', 'coordinates': [[[5.430089...\n",
       "01004    {'type': 'Polygon', 'coordinates': [[[5.386190...\n",
       "01005    {'type': 'Polygon', 'coordinates': [[[4.895580...\n",
       "01006    {'type': 'Polygon', 'coordinates': [[[5.614854...\n",
       "01007    {'type': 'Polygon', 'coordinates': [[[5.413533...\n",
       "01008    {'type': 'Polygon', 'coordinates': [[[5.321986...\n",
       "01009    {'type': 'Polygon', 'coordinates': [[[5.656393...\n",
       "                               ...                        \n",
       "97610    {'type': 'Polygon', 'coordinates': [[[45.23692...\n",
       "97611    {'type': 'Polygon', 'coordinates': [[[45.19781...\n",
       "97612    {'type': 'MultiPolygon', 'coordinates': [[[[45...\n",
       "97613    {'type': 'Polygon', 'coordinates': [[[45.10168...\n",
       "97614    {'type': 'Polygon', 'coordinates': [[[45.15401...\n",
       "97615    {'type': 'Polygon', 'coordinates': [[[45.29645...\n",
       "97616    {'type': 'Polygon', 'coordinates': [[[45.13226...\n",
       "97617    {'type': 'Polygon', 'coordinates': [[[45.15256...\n",
       "Name: geo_shape, Length: 36742, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GEO_SHAPE\n",
    "\n",
    "# La variable GEO_SHAPE doit contenir une Serie\n",
    "# correspondant aux valeurs de la colonne \"geo_shape\" parsées avec la librairie json\n",
    "import json\n",
    "\n",
    "GEO_SHAPE = GEO['geo_shape'].apply(json.loads)\n",
    "GEO_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts des valeurs \"type\"\n",
    "def get_types():\n",
    "    return GEO_SHAPE.apply(lambda x: x['type']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polygon         36670\n",
       "MultiPolygon       72\n",
       "Name: geo_shape, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts des longueurs de \"coordinates\"\n",
    "def get_coordinates_len():\n",
    "    return GEO_SHAPE.apply(lambda x: x['coordinates']).apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    36660\n",
       "2       80\n",
       "3        1\n",
       "4        1\n",
       "Name: geo_shape, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coordinates_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commune constituée du plus grand nombre de polygones\n",
    "def get_most_complex_city():\n",
    "    return GEO.loc[GEO_SHAPE.apply(lambda x: x['coordinates']).apply(len).idxmax(), \"cp_ville\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'83400 HYERES'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_complex_city()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de villes de type \"Polygon\" dont la longueur des listes accédées avec la clé \"coordinates\" vaut 2\n",
    "def get_nb_cities_2_polygons():\n",
    "    return (GEO_SHAPE.apply(lambda x: x['type']=='Polygon') &\n",
    "            (GEO_SHAPE.apply(lambda x: x['coordinates']).apply(len)==2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nb_cities_2_polygons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarque\n",
    "# il faut rester dans pandas pour effectuer des sélections\n",
    "# notamment en utilisant les opérateurs logiques (cf. SQL)\n",
    "# penser également à additionner les booléens et aux méthodes all() et any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérification que ce sont des enclaves\n",
    "# universalité de numpy\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def check_enclaves():\n",
    "\n",
    "    def test_enclave(coordinates):\n",
    "        if len(coordinates)!=2:\n",
    "            return False\n",
    "        p1 = Polygon(coordinates[0])\n",
    "        p2 = Polygon(coordinates[1])\n",
    "        return p1.contains(p2)\n",
    "\n",
    "    selection = GEO_SHAPE.loc[GEO_SHAPE.apply(lambda x: x['type']=='Polygon') &\n",
    "                              (GEO_SHAPE.apply(lambda x: x['coordinates']).apply(len)==2)]\n",
    "\n",
    "    return selection.apply(lambda x: test_enclave(x['coordinates'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_enclaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "import unittest\n",
    "\n",
    "class Session2Test(unittest.TestCase):\n",
    "    \n",
    "    def test_partie_A1(self):\n",
    "        # on applique la fonction cherche_ville() à une coordonnée tirée au hasard\n",
    "        np.random.seed(0)\n",
    "        a, b = 41.5, 51.1  # latitude min et max de la France métropolitaine\n",
    "        lat = np.random.uniform(a, b)\n",
    "        a, b = -5.1, 9.5  # longitude min et max de la France métropolitaine\n",
    "        lon = np.random.uniform(a, b)\n",
    "\n",
    "        cp_ville = search_city(lat, lon)\n",
    "        self.assertEqual(cp_ville, \"71330 BOSJEAN\")\n",
    "        \n",
    "    def test_partie_A2(self):\n",
    "        # à partir de coordonnées GPS précises\n",
    "        cp_ville = search_city(dms2dec(48, 42, 52), dms2dec(2, 14, 45))\n",
    "        self.assertEqual(cp_ville, \"91120 PALAISEAU\")\n",
    "        \n",
    "    def test_partie_B1(self):\n",
    "        # check types\n",
    "        dico = get_types()\n",
    "        self.assertEqual(dico[\"Polygon\"], 36670)\n",
    "        self.assertEqual(dico[\"MultiPolygon\"], 72)\n",
    "        \n",
    "    def test_partie_B2(self):\n",
    "        # check coordinates len\n",
    "        dico = get_coordinates_len()\n",
    "        self.assertEqual(dico[1], 36660)\n",
    "        self.assertEqual(dico[2], 80)\n",
    "       \n",
    "    def test_partie_B3(self):\n",
    "        # check most complex city\n",
    "        cp_ville = get_most_complex_city()\n",
    "        self.assertEqual(cp_ville, \"83400 HYERES\")\n",
    "        \n",
    "    def test_partie_B4(self):\n",
    "        # check nb cities 2 polygons\n",
    "        nb = get_nb_cities_2_polygons()\n",
    "        self.assertEqual(nb, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_partie_A1 (__main__.Session2Test) ... ok\n",
      "test_partie_A2 (__main__.Session2Test) ... ok\n",
      "test_partie_B1 (__main__.Session2Test) ... ok\n",
      "test_partie_B2 (__main__.Session2Test) ... ok\n",
      "test_partie_B3 (__main__.Session2Test) ... ok\n",
      "test_partie_B4 (__main__.Session2Test) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.287s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# run tests\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Session2Test)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)\n",
    "    \n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
