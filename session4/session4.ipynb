{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Télécom Paris - Kit Data Science - Session 4\n",
    "\n",
    "1. **Parsing XML**\n",
    "2. **Web scraping et parsing HTML**\n",
    "3. **API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Parsing XML (Extensible Markup Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation : https://fr.wikipedia.org/wiki/Extensible_Markup_Language\n",
    "\n",
    "Librairie lxml : https://lxml.de/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "\n",
    "Les 150 propositions de la Convention Citoyenne pour le Climat\n",
    "\n",
    "https://www.data.gouv.fr/fr/datasets/les-150-propositions-de-la-convention-citoyenne-pour-le-climat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing XML\n",
    "root = etree.parse('propositions.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un élément\n",
    "element = root.find('categorie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent\n",
    "element.getparent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribut\n",
    "element.attrib['titre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trouver un élément\n",
    "element = root.find('categorie').find('sousCategorie').find('proposition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "element.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de catégories: getiterator\n",
    "len([node for node in root.getiterator('categorie')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de sous-catégories: getiterator\n",
    "len([node for node in root.getiterator('sousCategorie')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de propositions: getiterator\n",
    "len([node for node in root.getiterator('proposition')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print categorie / sousCategorie / proposition\n",
    "for node_categorie in root.getiterator('categorie'):\n",
    "    \n",
    "    print(node_categorie.attrib['titre'])\n",
    "    \n",
    "    for node_sousCategorie in node_categorie.getiterator('sousCategorie'):\n",
    "        \n",
    "        print('> ', node_sousCategorie.attrib['titre'])\n",
    "        \n",
    "        for node_proposition in node_sousCategorie.getiterator('proposition'):\n",
    "            \n",
    "            print('>> ', node_proposition.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabrication d'un DataFrame à partir d'une liste de dict\n",
    "liste = [\n",
    "        {'a': 1, 'b': 2},\n",
    "        {'a': 3, 'b': 4},\n",
    "        {'a': 5, 'b': 6, 'c': 7},\n",
    "]\n",
    "\n",
    "pd.DataFrame(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabrication d'un DataFrame à partir du XML\n",
    "liste = [\n",
    "    {'categorie': node_category.attrib['titre'],\n",
    "    'sousCategorie': node_subcategory.attrib['titre'],\n",
    "    'proposition': node_proposition.text}\n",
    "        for node_category in root.getiterator('categorie')\n",
    "            for node_subcategory in node_category.getiterator('sousCategorie')\n",
    "                for node_proposition in node_subcategory.getiterator('proposition')]\n",
    "liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabrication d'un DataFrame à partir du XML\n",
    "liste = [\n",
    "    {'categorie': node_category.attrib['titre'],\n",
    "    'sousCategorie': node_subcategory.attrib['titre'],\n",
    "    'proposition': node_proposition.text}\n",
    "        for node_category in root.getiterator('categorie')\n",
    "            for node_subcategory in node_category.getiterator('sousCategorie')\n",
    "                for node_proposition in node_subcategory.getiterator('proposition')]\n",
    "\n",
    "df = pd.DataFrame(liste)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catégories\n",
    "df['categorie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requêtes\n",
    "df['proposition'].str.contains('biodiversité').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requêtes\n",
    "print(*df.loc[df['proposition'].str.contains('biodiversité'), 'proposition'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requêtes\n",
    "df['proposition'].str.contains('énergie').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requêtes\n",
    "print(*df.loc[df['proposition'].str.contains('énergie'), 'proposition'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on stocke les propositions pour plus tard\n",
    "propositions = df['proposition'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1**\n",
    "\n",
    "Produire un DataFrame avec les colonnes : categorie, sousCategorie, oui (float)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2**\n",
    "\n",
    "- Produire un DataFrame avec les colonnes : categorie, sousCategorie, oui (float), non (float), blancs (float).\n",
    "- Calculer les sommes oui + non + blancs et oui + non &#9786;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3**\n",
    "\n",
    "- Calculer un dictionnaire fréquentiel des mots  des propositions.\n",
    "- Le mettre dans un objet de type Series trié par fréquences décroissantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.findall()\n",
    "import re\n",
    "re.findall('[A-Za-zÀ-ÿ0-9]+', 'la fonction findall est très utile.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter\n",
    "from collections import Counter\n",
    "c = Counter()\n",
    "c.update(re.findall('[A-Za-zÀ-ÿ0-9]+', 'la fonction findall est très utile.'))\n",
    "c.update(re.findall('[A-Za-zÀ-ÿ0-9]+', 'un objet Counter est aussi très utile.'))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "var = propositions.apply(lambda x: re.findall('[A-Za-zÀ-ÿ0-9]+', x.lower()))\n",
    "var.apply(c.update)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_fr = stopwords.words('french')\n",
    "stopwords_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(c)\n",
    "s = s.drop(stopwords_fr, errors='ignore')\n",
    "s = s.sort_values(ascending=False)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation XML / XSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe un langage de description de schéma XML appelé XSD (XML Schema Definition). Un fichier XML peut être écrit selon un schéma XSD particulier. Il existe une librairie Python qui peut vérifier qu'un fichier XML est valide selon un schéma XSD donné.\n",
    "\n",
    "Librairie xmlschema :\n",
    "https://pypi.org/project/xmlschema/\n",
    "\n",
    "L'utilisation de la librairie est assez simple :\n",
    "\n",
    "<pre>\n",
    ">>> # vérification que le fichier \"file.xml\" est valide dans le schéma \"schema.xsd\"\n",
    ">>> import xmlschema\n",
    ">>> my_schema = xmlschema.XMLSchema('schema.xsd')\n",
    ">>> #\n",
    ">>> # retourne un booléen selon la validité\n",
    ">>> my_schema.is_valid('file.xml')\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Web Scraping\n",
    "\n",
    "- Extraction d'informations d'un site web.\n",
    "- A utiliser en l'absence de données ouvertes ou d'API.\n",
    "- Technique fragile car le site web peut changer du jour au lendemain.\n",
    "- Problématique juridique...\n",
    "\n",
    "**Avec requests**\n",
    "\n",
    "Doc :\n",
    "- requests : https://requests.readthedocs.io/en/master/\n",
    "\n",
    "Installation :\n",
    "- *pip install requests* ou *conda install -c anaconda requests*\n",
    "\n",
    "Exemple de site : https://www.beerwulf.com/fr-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://www.beerwulf.com/fr-fr')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str en précisant un encodage\n",
    "content = r.content.decode('utf-8')\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essai avec des regex\n",
    "\n",
    "On cherche: `<span class=\"price\">...</span>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle d'un prix avec une regex\n",
    "# extraction de tous les caractères différents de <\n",
    "# compris entre <span class=\"price\"> et </span>\n",
    "rx = re.compile('<span class=\"price\">([^<]+)</span>')\n",
    "match = rx.search(content)  # équivalent à match = re.search('<span class=\"price\">([^<]+)</span>', content)\n",
    "type(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction de niveau 0\n",
    "match.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction de niveau 1\n",
    "match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La technique est très fragile car elle s'appuie sur la syntaxe HTML exacte et non sur la sémantique..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "rx = re.compile('<span class=\"price from-price strike-through\">([^<]+)</span>')\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération mannuelle de tous les prix avec une regex\n",
    "# ( from-price)? est une expression de capture\n",
    "# possibilité d'utiliser (?: from-price)? qui n'est pas une expression de capture\n",
    "rx = re.compile('<span class=\"price( from-price)?( strike-through)?\">([^<]+)</span>')\n",
    "for match in rx.finditer(content):\n",
    "    print(match.group(1), match.group(2), match.group(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avec pandas.read_html()** recherche des tableaux dans les pages HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple**\n",
    "\n",
    "Tableau page wikipédia: https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping d'une page HTML\n",
    "var = pd.read_html(\"https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal\")\n",
    "[df.shape for df in var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès au n° 2\n",
    "df = var[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à des valeurs\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = columns du DataFrame\n",
    "df.iloc[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à des valeurs\n",
    "df.iloc[[0, 1, 2, 76, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès à une valeur\n",
    "df.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher le code hexa \\xa0 : https://www.codetable.net/hex/a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aide sur read_html()\n",
    "pd.read_html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion automatique du séparateur des milliers\n",
    "var = pd.read_html(\"https://fr.wikipedia.org/wiki/Liste_des_pays_par_PIB_nominal\",\n",
    "                    thousands='\\xa0',\n",
    "                    decimal=',')\n",
    "df = var[1]\n",
    "df.iloc[[0, 1, 2, 76, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reste à faire\n",
    "df.loc[df['Pays ou territoire'].str.contains(\"[^A-Za-zÀ-ÿ0-9 \\-']\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reste à faire :\n",
    "\n",
    "Extraire les noms des pays sans les annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avec beautifulsoup** parsing HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc :\n",
    "- beautifulsoup : https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "Installation :\n",
    "- *pip install beautifulsoup4* ou *conda install -c anaconda beautifulsoup4*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple basique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head>\n",
    "        <style>\n",
    "        h1 { font-size: 50px; }\n",
    "        body { font-family: Verdana; }\n",
    "        li { color: red; }\n",
    "        ul ul li { color: green; }\n",
    "        .highlighted { font-weight: bold; }\n",
    "        .italic { font-style: italic; }\n",
    "        .highlighted.italic { }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Mon titre</h1>\n",
    "        <p class=\"highlighted\">\n",
    "            Some text with a<br>\n",
    "            <a href=\"https://google.com\">link to google</a>\n",
    "            <img src=\"https://picsum.photos/200/300\">\n",
    "        </p>\n",
    "        <p>Some list:</p>\n",
    "        <ul>\n",
    "            <li>some item</li>\n",
    "            <li class=\"highlighted italic\">some item</li>\n",
    "            <li class=\"italic\">some item</li>\n",
    "            <ul>\n",
    "                <li>some other item 1</li>\n",
    "                <li>some other item 2</li>\n",
    "            </ul>\n",
    "            <li>some item</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tester sur : https://html.house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4\n",
    "soup = BeautifulSoup(html)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find h1\n",
    "titre = soup.find('h1')\n",
    "titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(titre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name\n",
    "titre.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "titre.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a\n",
    "link = soup.find('a')\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prochain tag\n",
    "link.find_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link.find_next().find_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrs\n",
    "link.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "link.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find p\n",
    "paragraph = soup.find('p')\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find img in paragraph\n",
    "paragraph.find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all\n",
    "soup.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all\n",
    "soup.find_all('li', {'class': \"italic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idem avec un sélecteur css:\n",
    "soup.select('li.italic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les li de 2e niveau qui sont dans un ul lui-même dans un ul\n",
    "soup.find('ul').find('ul').find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idem avec un sélecteur css:\n",
    "soup.select('ul ul li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accès au premier li\n",
    "li = soup.select('ul ul li')[0]\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prochain tag identique\n",
    "li.find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent\n",
    "li.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents\n",
    "li.parent.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# que les tags\n",
    "li.parent.find_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple 1**\n",
    "\n",
    "Le Bon Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# premier essai avec leboncoin\n",
    "\n",
    "r = requests.get('https://www.leboncoin.fr/annonces/offres/ile_de_france/')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codes erreurs du protocole HTTP : https://developer.mozilla.org/fr/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contenu\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en str\n",
    "print(r.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers\n",
    "headers = requests.utils.default_headers()\n",
    "headers.update({'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "               'Accept-Language': 'fr,fr-FR;',})\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd essai avec leboncoin\n",
    "r = requests.get('https://www.leboncoin.fr/annonces/offres/ile_de_france/',\n",
    "                 headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple 2**\n",
    "\n",
    "Craig List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essai avec craigslist\n",
    "r = requests.get('https://paris.craigslist.org/d/locations-de-vacances/search/vac',\n",
    "                 headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Paris Locations de vacances - craigslist.htm', 'rb') as f:\n",
    "    content = f.read()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup\n",
    "soup = BeautifulSoup(content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise 2 méthodes :\n",
    "    \n",
    "- `find(tag, attrs)` : trouve le premier tag avec les attributs spécifiés\n",
    "- `findAll(tag, attrs)` : trouve tous les tags avec les attributs spécifiés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration du HTML\n",
    "# tag li avec class=\"result-row\"\n",
    "\n",
    "li_tag = soup.find('li', attrs={'class': 'result-row'})\n",
    "print(li_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(li_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La technique consiste par exemple à alimenter une liste de dictionnaires avec les valeurs trouvées pour chaque item et ensuite à le transformer en DataFrame :\n",
    "- soit en utilisant `tag.attrs['attr']` pour collecter la valeur attr du tag <tag attr=value>\n",
    "- soit en utilisant `tag.text` pour collecter la valeur <tag>text</tag>\n",
    "- éventuellement en recherchant dans un nouveau tag à l'intérieur d'un tag donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecte des informations\n",
    "# \"data-pid\"\n",
    "# \"time\"\n",
    "# \"title\"\n",
    "# \"price\"\n",
    "# \"housing\"\n",
    "# \"hood\"\n",
    "# \"data-ids\" (images)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for li_tag in soup.findAll('li', attrs={'class': 'result-row'}):\n",
    "    row = {}\n",
    "    row['data-pid'] = li_tag.attrs['data-pid']\n",
    "    t = li_tag.find('time')\n",
    "    row['datetime'] = t.attrs['datetime']\n",
    "    # à compléter\n",
    "    rows.append(row)\n",
    "    \n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4**\n",
    "\n",
    "Compléter le DataFrame (sauf images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inconvénients du web scraping:\n",
    "- plutôt lent (car on parse potentiellement beaucoup de HTML inutile)\n",
    "- ne donne pas les résultats attendus si une partie du contenu est intégré dynamiquement à la page via javascript\n",
    "- un changement dans l'architecture du html ou du css (e.g: refonte du design du site) oblige à réécrire entièrement le programme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "\n",
    "Exemple: Deezer\n",
    "\n",
    "Artiste : https://www.deezer.com/fr/artist/3037\n",
    "\n",
    "Récupérer le nombre de fans d'un artiste avec requests :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# request\n",
    "artist = 3037\n",
    "response = requests.get(f'https://www.deezer.com/fr/artist/{artist}')\n",
    "soup = BeautifulSoup(response.content)\n",
    "nb_fans = int(soup.find('div', id='naboo_artist_social_small').span.text)\n",
    "nb_fans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer le nombre de fans d'un artiste avec l'API :\n",
    "\n",
    "Doc:\n",
    "- https://pypi.org/project/deezer-python/\n",
    "\n",
    "Installation :\n",
    "- *pip install deezer-python*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le terme \"API\" est très générique et peut désigner bien des choses, mais dans le jargon on l'utilise souvent pour désigner un service web qui renvoie non pas:\n",
    "> des pages web au format HTML (destinées à être lues par un humain dans son navigateur)\n",
    "\n",
    "mais:\n",
    "> des données au format JSON (destinées à être traitées par un programme)\n",
    "\n",
    "![img](https://miro.medium.com/max/4238/1*OcmVkcsM5BWRHrg8GC17iw.png)\n",
    "\n",
    "Puisque les API sont dédiées à l'usage via des programmes, elles disposent en général d'une bonne documentation, et sont fiables et stables dans le temps. Tandis que sur des pages web HTML classiques, le design peut par exemple changer du jour au lendemain et rendre votre programme BeautifulSoup obsolète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API JSON\n",
    "response = requests.get(f'https://api.deezer.com/artist/{artist}')\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_fan\n",
    "data['nb_fan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture\n",
    "from IPython.display import Image\n",
    "url = data['picture']\n",
    "r = requests.get(url)\n",
    "Image(data=r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avantages d'une API\n",
    "- renvoie du format JSON, facile et rapide à traiter\n",
    "- renvoie un format stable et documenté (voire versionné)\n",
    "- exemple : https://developer.twitter.com/en/docs/twitter-api/api-reference-index\n",
    "- la documentation indique comment interagir avec l'API:\n",
    "    - quelle url\n",
    "    - quelle méthode http (GET, POST, ...)\n",
    "    - quels paramètres\n",
    "    - ...\n",
    "→ idéal pour les développeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quel intérêt pour le fournisseur d'API ?\n",
    "\n",
    "En général il met en place des quotas de requêtes ou d'autres limitations afin de proposer un service payant qui dispose de possibilités avancées / d'un meilleur support / etc.\n",
    "\n",
    "C'est pourquoi de nombreux services nécessitent de se connecter avec son compte client pour utiliser une API (e.g. https://openweathermap.org/api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basic Auth**\n",
    "\n",
    "Exemple: accéder à https://kim.fspot.org/private/\n",
    "\n",
    "Pour y accéder il est nécessaire d'utiliser les credentials suivant:\n",
    "- login: admin\n",
    "- password: secret\n",
    "\n",
    "Si on ne les passe pas (ou si on ne passe pas les bons), on a une erreur 401 (= unauthorized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sans login/password\n",
    "res = requests.get('https://kim.fspot.org/private')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avec login password\n",
    "res = requests.get('https://kim.fspot.org/private', auth=('admin', 'secret'))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contenu\n",
    "res.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML pour masquer auth crendentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auth par token\n",
    "\n",
    "Exemple sur openweathermap :\n",
    "- documentation: https://openweathermap.org/appid\n",
    "- mes tokens: https://home.openweathermap.org/api_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requête avec un token\n",
    "token = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantage des tokens:\n",
    "- évite que les requêtes HTTP contiennent le mot de passe - à la place elles contiennent un token\n",
    "- si je me fais \"voler\" un token, je peux le supprimer de mon compte\n",
    "- certains services fournissent des token plus ou moins limités : ainsi je peux accepter de prêter un token à quelqu'un d'autre si je sais qu'il ne pourra en faire qu'un usage restreint (e.g app facebook: voir mes infos de profil, pas publier des posts à ma place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requête avec un token\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?APPID={token}&q=Paris'\n",
    "res = requests.get(url)\n",
    "\n",
    "meteo = res.json()\n",
    "meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type\n",
    "type(meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractions\n",
    "{'city': meteo['name'],\n",
    "'country': meteo['sys']['country'],\n",
    "'date': meteo['dt'],\n",
    "'temp': meteo['main']['temp'] - 273.15,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractions\n",
    "import time\n",
    "\n",
    "{'city': meteo['name'],\n",
    "'country': meteo['sys']['country'],\n",
    "'date': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(meteo['dt'])),\n",
    "'temp': meteo['main']['temp'] - 273.15,}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
